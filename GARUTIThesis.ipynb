{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GARUTIThesis.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vK_LJMRy7X6n"
      },
      "source": [
        "#import modules here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import gdown\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, LSTM\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.utils import shuffle\n",
        "from tensorflow import keras\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bwq0Q-skKyqv"
      },
      "source": [
        "#Time Aware layer for T_LSTM models:\n",
        "'''\n",
        "TLSTM_layer is obtained from the following Github Repository:\n",
        "\n",
        "Nguyen, A., Chatterjee, S., Weinzierl, S., Schwinn, L., Matzner, M., & Eskofier, B.(2020).\n",
        "Time matters: Time-aware lstms for predictive business processmonitoring; TLSTM_layer [Source Code]. Retrievable at:\n",
        "https://github.com/annguy/time-aware-pbpm/blob/master/src/Models/TLSTM_layer.py. [Accessed on May 21st, 2021]\n",
        "\n",
        "The MIT License (MIT)\n",
        "Copyright (c) 2020, An Nguyen, Srijeet Chatterjee\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy of \n",
        "this software and associated documentation files (the \"Software\"),\n",
        "to deal in the Software without restriction, including without limitation the rights to use,\n",
        "copy, modify, merge, publish, distribute, sublicense, and/or sell copies of the Software,\n",
        "and to permit persons to whom the Software is furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all copies\n",
        "or substantial portions of the Software.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED\n",
        "TO THE WARRANTIES OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT.\n",
        "IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY,\n",
        "WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN CONNECTION WITH THE SOFTWARE\n",
        "OR THE USE OR OTHER DEALINGS IN THE SOFTWARE.\n",
        "\n",
        "Link for detailed installation instructions of conda environment: https://github.com/annguy/time-aware-pbpm\n",
        "'''\n",
        "!pip install kora -q\n",
        "from kora import drive\n",
        "drive.link_nbs()\n",
        "import import_ipynb\n",
        "import src\n",
        "from src import TLSTM_layer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmjDtqiYQJeY"
      },
      "source": [
        "#Dataset\n",
        "'''\n",
        "The full dataset can be downloaded following this Github link:\n",
        "\n",
        "Requena, B., Cassani, G., Tagliabue, J., Greco, C., & Lacasa, L. (2020).\n",
        "Shopper intentprediction from clickstream e-commerce data with minimal browsing information.\n",
        "https://github.com/coveooss/shopper-intent-prediction-nature-2020\n",
        "'''\n",
        "\n",
        "df = pd.read_csv('./release_10_23_2020.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJHFZxt3AjPL"
      },
      "source": [
        "## Pre-processing function\n",
        "def preprocess(df):\n",
        "\n",
        "  # rename actions\n",
        "  df['product_action'] = df['product_action'].replace([np.nan,'detail', 'add', 'remove', 'click', 'purchase',],[1,2,3,4,5,7])\n",
        "\n",
        "  # make sequences\n",
        "  df = df.groupby('session_id_hash')[['product_action', 'server_timestamp_epoch_ms']].agg(list).reset_index()\n",
        "\n",
        "  #make labels\n",
        "  df['label'] = np.where(df.product_action.map(set([7]).issubset), 0, 1)\n",
        "  \n",
        "  #trim sequences after first purchase event\n",
        "  def trim(df):\n",
        "    sequence_action = []\n",
        "    timestamp = []\n",
        "    for item, time in zip(df.product_action, df.server_timestamp_epoch_ms):\n",
        "      if 7 in set(item):\n",
        "        for e in range(len(item)):\n",
        "          if item[e] == 7:\n",
        "            item1 = item[: e]\n",
        "            sequence_action.append(item1)\n",
        "            time1 = time[: e] \n",
        "            timestamp.append(time1)\n",
        "            break\n",
        "      else:\n",
        "        sequence_action.append(item)\n",
        "        timestamp.append(time)\n",
        "    df['sequence_action'] = sequence_action\n",
        "    df['timestamp'] = timestamp\n",
        "    return df\n",
        "  trim(df)\n",
        "\n",
        "  #rearrange column order and drop old product_action column\n",
        "  df = df[['session_id_hash', 'sequence_action', 'timestamp', 'label']]\n",
        "\n",
        "  #drop sequences shorter than 5 and longer than 155\n",
        "  index_to_drop = []\n",
        "  for id, row in df.iterrows():\n",
        "    if len(row[1]) < 5 or len(row[1]) > 155:\n",
        "      index_to_drop.append(id)\n",
        "  df = df.drop(df.index[index_to_drop])\n",
        "\n",
        "  #add exit event\n",
        "  def add_exit(df):\n",
        "    sequence_exit = []\n",
        "    for id, row in df.iterrows():\n",
        "      row[1] = [0] + row[1] + [6]\n",
        "      sequence_exit.append(row[1])\n",
        "    df['sequence_exit'] = sequence_exit\n",
        "    return df\n",
        "  add_exit(df)\n",
        "\n",
        "  # add durations\n",
        "  def delta(df):\n",
        "    delta = []\n",
        "    for t in df['timestamp']:\n",
        "      v = [0] + list(np.diff([t[0]] + t))\n",
        "      v = np.asarray(v)\n",
        "      delta.append(v)\n",
        "    df['delta'] = delta\n",
        "    return df\n",
        "  delta(df)\n",
        "  \n",
        "  #reset index\n",
        "  df = df[['session_id_hash', 'sequence_exit', 'timestamp', 'delta', 'label']]\n",
        "  df = df.reset_index()\n",
        "  df.drop('index', inplace=True, axis=1)\n",
        "\n",
        "  return df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q_blMhKlRyRB"
      },
      "source": [
        "### Preprocess Dataframe\n",
        "df2 = preprocess(df)\n",
        "df2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZTAV-acqO1l",
        "outputId": "229587ba-b187-4187-b54c-87782be9ea1d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AGZnkc861liR"
      },
      "source": [
        "#plot average time on site\n",
        "average_time_on_site = []\n",
        "for row in df2['timestamp']:\n",
        "  average_time_on_site.append(row[-1]-row[0])\n",
        "q25, q75 = np.percentile(average_time_on_site,[.25,.75])\n",
        "bin_width = 2*(q75 - q25)*len(average_time_on_site)**(-1/3)\n",
        "average_time_on_site = np.asarray(average_time_on_site)\n",
        "bins = round((average_time_on_site.max() - average_time_on_site.min())/bin_width)\n",
        "print(\"Freedmanâ€“Diaconis number of bins:\", bins)\n",
        "plt.hist(average_time_on_site, density=True, bins=100)  # density=False would make counts\n",
        "plt.ylabel('Frequency')\n",
        "plt.xlabel('Time spent on the website');"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb9d44YP5S6-"
      },
      "source": [
        "#time plot\n",
        "average_time_on_site = np.asarray(average_time_on_site)\n",
        "average_time_on_site= average_time_on_site/1000\n",
        "average_duration = []\n",
        "for row in df2['delta']:\n",
        "  row = np.asarray(row[2:])\n",
        "  mean = np.mean(row)\n",
        "  if mean < 500:\n",
        "    average_duration.append(mean)\n",
        "average_duration = np.asarray(average_duration)\n",
        "plt.hist(average_duration, density=False, bins=150, color = \"skyblue\", )  # density=False would make counts\n",
        "plt.ylabel('counts')\n",
        "plt.xlabel('average time spent on page');\n",
        "plt.title(\"Average time between consecutive actions\", size = 15, pad = 10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HS4TEQpoAslV"
      },
      "source": [
        "average_d = pd.DataFrame()\n",
        "average_d['average duration'] = average_duration"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qENpK_y37EHX"
      },
      "source": [
        "print(np.mean(average_duration))\n",
        "print(np.std(average_duration))\n",
        "print(max(average_duration))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jXJbmw0oIcyU"
      },
      "source": [
        "#Bar plot\n",
        "view_c = 0\n",
        "detail_c= 0\n",
        "add_c= 0\n",
        "remove_c= 0\n",
        "click_c= 0\n",
        "view_nc= 0\n",
        "detail_nc= 0\n",
        "add_nc= 0\n",
        "remove_nc= 0\n",
        "click_nc= 0\n",
        "for id, row in df2.iterrows():\n",
        "  if row[4]==0:\n",
        "    for i in row[1]:\n",
        "      if i == 1:\n",
        "        view_c +=1\n",
        "      elif i == 2:\n",
        "        detail_c +=1\n",
        "      elif i == 3:\n",
        "        add_c +=1\n",
        "      elif i == 4:\n",
        "        remove_c +=1\n",
        "      elif i == 5:\n",
        "        click_c +=1\n",
        "  elif row[4]==1:\n",
        "    for i in row[1]:\n",
        "      if i == 1:\n",
        "        view_nc +=1\n",
        "      elif i == 2:\n",
        "        detail_nc +=1\n",
        "      elif i == 3:\n",
        "        add_nc +=1\n",
        "      elif i == 4:\n",
        "        remove_nc +=1\n",
        "      elif i == 5:\n",
        "        click_nc +=1\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "conversion = (view_c,detail_c,add_c,remove_c,click_c)\n",
        "non_conversion = (view_nc,detail_nc,add_nc,remove_nc,click_nc)\n",
        "ind = ('view','detail','add','remove','click') # the x locations for the groups\n",
        "width = 0.35\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "ax.bar(ind, non_conversion, width, color='r')\n",
        "ax.bar(ind, conversion, width,bottom=non_conversion , color='b')\n",
        "ax.set_ylabel('Counts (in 100k)')\n",
        "ax.set_title('Action events number by class',size = 15, pad = 10)\n",
        "ax.set_xticks(ind, ('G1', 'G2', 'G3', 'G4', 'G5'))\n",
        "ax.set_yticks(np.arange(0, 3000000, 300000))\n",
        "ax.legend(labels=['Non-onversion', 'Conversion'])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4rpNsbsk0ZFf"
      },
      "source": [
        "## histogram\n",
        "length_sequences_C = []\n",
        "length_sequences_NC = []\n",
        "\n",
        "tot0 = df2[df2['label'] == 0].shape[0]\n",
        "tot1 = df2[df2['label'] == 1].shape[0]\n",
        "\n",
        "for item, y in zip(df2.sequence_exit, df2.label):\n",
        "  if y == 0:\n",
        "    length_sequences_C.append(len(item))\n",
        "  else:\n",
        "    length_sequences_NC.append(len(item))\n",
        "\n",
        "plt.figure(figsize=(14,6))\n",
        "\n",
        "plt.hist(length_sequences_NC, bins=150, alpha=0.4, label=\"Non- conversion sequences\", density=True, color = \"g\")\n",
        "plt.hist(length_sequences_C, bins=150, alpha=0.4, label=\"Conversion sequences\", density=True, color = \"orange\")\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.xlabel(\"Timesteps\", size=14)\n",
        "plt.ylabel(\"Probabilities\", size=14)\n",
        "plt.title(\"Histogram of Conversion and Non-conversion Trajectories \")\n",
        "plt.legend(loc='upper right')\n",
        "#plt.savefig(\"overlapping_histograms_with_matplotlib_Python.png\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MM4vo-_Ol_4L"
      },
      "source": [
        "#plot class imbalance\n",
        "pd.value_counts(df_1['label']).plot.bar()\n",
        "plt.title('Label histogram')\n",
        "plt.xlabel('Label')\n",
        "plt.ylabel('Frequency')\n",
        "df_1['label'].value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vm_wnaL7U0Z"
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import sklearn\n",
        "import numpy as np\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "num_classes = 7\n",
        "maxlen = 157\n",
        "\n",
        "X1 = []\n",
        "for sequence in df2['sequence_exit']:\n",
        "  X1.append(to_categorical(sequence, num_classes = num_classes))\n",
        "lol = X1\n",
        "X1 = pad_sequences(X1, maxlen = maxlen, value = 0)\n",
        "X2 = pad_sequences(df2['delta'], maxlen -1, value = -1)\n",
        "X3 = df2['timestamp']\n",
        "\n",
        "new_X = []\n",
        "new_y = []\n",
        "for x in X1:\n",
        "  new_X.append(x[:-1])\n",
        "  new_y.append(x[1:])\n",
        "\n",
        "new_X = np.asarray(new_X)\n",
        "new_y = np.asarray(new_y)\n",
        "\n",
        "\n",
        "X = pd.DataFrame({'new_X': list(new_X), 'X2': list(X2), 'X3': list(X3), 'new_y': list(new_y)}, columns=['new_X', 'X2', 'X3', 'new_y'])\n",
        "\n",
        "y = df2['label']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbn_8kFrotRs"
      },
      "source": [
        "#test train split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train1, X_val1, y_train1, y_val1 = train_test_split(X, y, test_size=0.3, random_state=42, stratify = y)\n",
        "X_val2, X_test2, y_val2, y_test2 = train_test_split(X_val1, y_val1, test_size=0.5, random_state=42, stratify = y_val1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bm3Ik66XpKFp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4937fb6-99f9-498d-a5b4-525a74638173"
      },
      "source": [
        "#label sets\n",
        "\n",
        "from numpy import where\n",
        "from collections import Counter\n",
        "\n",
        "\n",
        "y_train = pd.DataFrame()\n",
        "y_train['new_y'] = X_train1['new_y']\n",
        "\n",
        "y_train['y_label'] = y_train1\n",
        "\n",
        "y_val = pd.DataFrame()\n",
        "y_val['new_y'] = X_val2['new_y']\n",
        "\n",
        "y_val['y_label'] = y_val2\n",
        "\n",
        "y_test = pd.DataFrame()\n",
        "y_test['new_y'] = X_test2['new_y']\n",
        "\n",
        "y_test['y_label'] = y_test2\n",
        "\n",
        "# summarize the new class distribution\n",
        "counter = Counter(y_train)\n",
        "print(counter)\n",
        "\n",
        "print(len(X_train1))\n",
        "print(len(X_val2))\n",
        "print(len(X_test2))\n",
        "\n",
        "print(len(y_train1))\n",
        "print(len(y_val2))\n",
        "print(len(y_test2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counter({'new_y': 1, 'y_label': 1})\n",
            "142158\n",
            "30463\n",
            "30463\n",
            "142158\n",
            "30463\n",
            "30463\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WiBKDFw8vYda"
      },
      "source": [
        "#reshape all data\n",
        "X_train_new = np.stack(X_train1['new_X']).reshape((len(X_train1['new_X']), (maxlen -1 ) , num_classes)).astype(np.float32)\n",
        "X_val_new = np.stack(X_val2['new_X']).reshape((len(X_val2['new_X']), (maxlen -1 ), num_classes)).astype(np.float32)\n",
        "X_test_new = np.stack(X_test2['new_X']).reshape((len(X_test2['new_X']), (maxlen -1), num_classes)).astype(np.float32)\n",
        "X_train_delta = np.stack(X_train1['X2']).reshape((len(X_train1['X2']), maxlen-1)).astype(np.float32)\n",
        "X_val_delta = np.stack(X_val2['X2']).reshape((len(X_val2['X2']),maxlen -1)).astype(np.float32)\n",
        "X_test_delta = np.stack(X_test2['X2']).reshape((len(X_test2['X2']),maxlen -1)).astype(np.float32)\n",
        "X_train_time = np.asarray(X_train1['X3'])\n",
        "X_val_time = np.asarray(X_val2['X3'])\n",
        "X_test_time = np.asarray(X_test2['X3'])\n",
        "\n",
        "y_train_label = y_train['y_label']\n",
        "y_val_label = y_val['y_label']\n",
        "y_test_label = y_test['y_label']\n",
        "\n",
        "y_train_new = np.stack(y_train['new_y']).reshape((len(y_train['new_y']), (maxlen -1 ), num_classes)).astype(np.float32)\n",
        "y_val_new = np.stack(y_val['new_y']).reshape((len(y_val['new_y']), (maxlen -1), num_classes)).astype(np.float32)\n",
        "y_test_new = np.stack(y_test['new_y']).reshape((len(y_test['new_y']), (maxlen -1 ), num_classes)).astype(np.float32)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-qdN0fkPrwR"
      },
      "source": [
        "print(X_train_new.shape)\n",
        "print(X_val_new.shape)\n",
        "print(X_test_new.shape)\n",
        "print('---------------')\n",
        "print(X_train_delta.shape)\n",
        "print(X_val_delta.shape)\n",
        "print(X_test_delta.shape)\n",
        "print('---------------')\n",
        "print(y_train_new.shape)\n",
        "print(y_val_new.shape)\n",
        "print(y_test_new.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xiWMfGvzX9D9"
      },
      "source": [
        "#Discriminative specialised LSTM\n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization\n",
        "from keras import  Model\n",
        "\n",
        "main_input = Input(shape=(maxlen -1, num_classes), name='main_input')\n",
        "mask = Masking(mask_value = [0.,0.,0.,0.,0.,0.,0.], name = 'mask' )(main_input)\n",
        "# train a 2-layer LSTM with one shared layer\n",
        "l1 = LSTM(64, return_sequences=True)(mask)  # the shared layer\n",
        "b1 = BatchNormalization()(l1)\n",
        "\n",
        "l2_1 = LSTM(64, return_sequences=False)(b1)  # the layer specialized in activity prediction\n",
        "b2_1 = BatchNormalization()(l2_1)\n",
        "\n",
        "binary_output = Dense(1, activation='sigmoid', name='binary_output')(b2_1)\n",
        "\n",
        "model_SD = Model(inputs=[main_input], outputs=[binary_output])\n",
        "\n",
        "model_SD.compile(loss= 'binary_crossentropy',optimizer = 'adam', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7GRbeksYRj3"
      },
      "source": [
        "#Fit model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history_SD = model_SD.fit(X_train_new, y_train_label,\n",
        "                         validation_data = (X_val_new, y_val_label),\n",
        "                         verbose=1,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7fKpqFhet3Ez"
      },
      "source": [
        "# model predict\n",
        "y_pred_binary_SD = model_SD.predict(X_test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-_tSkZj2uXtI"
      },
      "source": [
        "#save model\n",
        "model_SD.save('model_SD.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88Zg0Du9ujfs"
      },
      "source": [
        "#load model\n",
        "model_SD = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Thesis/model_SD.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZA_ErvQRRS7"
      },
      "source": [
        "#TIME generative specialised TIME LSTM\n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization\n",
        "from keras import  Model\n",
        "\n",
        "main_input = Input(shape=(maxlen -1, num_classes), name='main_input')\n",
        "mask1 = Masking(mask_value = 0, name = 'mask1' )(main_input)\n",
        "# delta_ts: (batch_size, 1)\n",
        "delta_ts = Input(shape=(maxlen -1, ), name='delta_ts')\n",
        "mask2 = Masking(mask_value = -1, name = 'mask2' )(delta_ts)\n",
        "# train a 2-layer LSTM with one shared layer\n",
        "l1 = TLSTM_layer(64, return_sequence=True)(mask1,mask2)  # the shared layer\n",
        "b1 = BatchNormalization()(l1)\n",
        "\n",
        "l2_1 = TLSTM_layer(64, return_sequence=True)(b1,mask2)  # the layer specialized in activity prediction\n",
        "b2_1 = BatchNormalization()(l2_1)\n",
        "\n",
        "act_output = Dense(num_classes, activation='softmax', name='act_output')(b2_1)\n",
        "\n",
        "time_model_SG = Model(inputs=[main_input, delta_ts], outputs=[act_output])\n",
        "\n",
        "time_model_SG.compile(loss= 'categorical_crossentropy',optimizer = 'adam', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CW-9MdcLSO88"
      },
      "source": [
        "#Fit model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history_time_SG = time_model_SG.fit([X_train_new, X_train_delta], y_train_new,\n",
        "                         validation_data = ([X_val_new, X_val_delta], y_val_new),\n",
        "                         verbose=1,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8XylroSssPfu"
      },
      "source": [
        "y_pred_act_TIME_SG= time_model_SG.predict([X_test_new, X_test_delta])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Byh_QyjOrmfG"
      },
      "source": [
        "time_model_SG.save('time_model_SG.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ww1BHJA1uw-c"
      },
      "source": [
        "from src import TLSTM_layer\n",
        "time_model_SG = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Thesis/time_model_SG.h5', custom_objects={'TLSTM_layer':TLSTM_layer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkJgBEuALzky"
      },
      "source": [
        "#TIME discriminative specialised TIME LSTM\n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization, Lambda\n",
        "from keras import  Model\n",
        "from src import TLSTM_layer\n",
        "main_input = Input(shape=(maxlen -1, num_classes), name='main_input')\n",
        "mask1 = Masking(mask_value = 0, name = 'mask1' )(main_input)\n",
        "# delta_ts: (batch_size, 1)\n",
        "delta_ts = Input(shape=(maxlen -1, ), name='delta_ts')\n",
        "mask2 = Masking(mask_value = -1, name = 'mask2' )(delta_ts)\n",
        "# train a 2-layer LSTM with one shared layer\n",
        "l1 = TLSTM_layer(64, return_sequence=True)(mask1,mask2)  # the shared layer\n",
        "b1 = BatchNormalization()(l1)\n",
        "\n",
        "l2_2a = TLSTM_layer(64, return_sequence=True)(b1, mask2)\n",
        "l2_2 = Lambda(lambda x: x[:, -1, :])(l2_2a)\n",
        "b2_1 = BatchNormalization()(l2_2)\n",
        "\n",
        "binary_output = Dense(1, activation='sigmoid', name='act_output')(b2_1)\n",
        "\n",
        "time_model_SD = Model(inputs=[main_input, delta_ts], outputs=[binary_output])\n",
        "\n",
        "time_model_SD.compile(loss= 'binary_crossentropy',optimizer = 'adam', metrics = ['acc'])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGiPPqMSMMFi"
      },
      "source": [
        "#Fit model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history_time_SD = time_model_SD.fit([X_train_new, X_train_delta], y_train_label,\n",
        "                         validation_data = ([X_val_new, X_val_delta], y_val_label),\n",
        "                         verbose=1,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dz-xx0w2FnB3"
      },
      "source": [
        "# model predict\n",
        "y_pred_binary_TIME_SD = time_model_SD.predict([X_test_new, X_test_delta])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wpm1N5tcmuoR"
      },
      "source": [
        "time_model_SD.save('time_model_SD.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JtNJ_IlXFNOc"
      },
      "source": [
        "time_model_SD = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Thesis/time_model_SD.h5',custom_objects={'TLSTM_layer':TLSTM_layer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gW51k9h5X-Qm"
      },
      "source": [
        "#Generative specialised LSTM\n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization\n",
        "from keras import  Model\n",
        "\n",
        "main_input = Input(shape=(maxlen -1, num_classes), name='main_input')\n",
        "mask = Masking(mask_value = [0.,0.,0.,0.,0.,0.,0.], name = 'mask' )(main_input)\n",
        "# train a 2-layer LSTM with one shared layer\n",
        "l1 = LSTM(64, return_sequences=True)(mask)  # the shared layer\n",
        "b1 = BatchNormalization()(l1)\n",
        "\n",
        "l2_1 = LSTM(64, return_sequences=True)(b1)  # the layer specialized in activity prediction\n",
        "b2_1 = BatchNormalization()(l2_1)\n",
        "\n",
        "act_output = Dense(num_classes, activation='softmax', name='act_output')(b2_1)\n",
        "\n",
        "model_SG = Model(inputs=[main_input], outputs=[act_output])\n",
        "\n",
        "model_SG.compile(loss= 'categorical_crossentropy',optimizer = 'adam', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqXe-AsbHZii"
      },
      "source": [
        "#Fit model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history = model_SG.fit(X_train_new, y_train_new,\n",
        "                         validation_data = (X_val_new, y_val_new),\n",
        "                         verbose=1,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n3xQ6ZWcHx0K"
      },
      "source": [
        "# model predict\n",
        "y_pred_act_SG = model_SG.predict(X_test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RKtJ3AosvYcp"
      },
      "source": [
        "#save model\n",
        "model_SG.save('model_SG.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBLD23p3uirv"
      },
      "source": [
        "model_SG = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Thesis/model_SG.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftpb-d5U5bGz"
      },
      "source": [
        "## Gen and discriminative LSTM\n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization\n",
        "from keras import  Model\n",
        "\n",
        "main_input = Input(shape=(maxlen -1, num_classes), name='main_input')\n",
        "mask = Masking(mask_value = [0.,0.,0.,0.,0.,0.,0.], name = 'mask' )(main_input)\n",
        "# train a 2-layer LSTM with one shared layer\n",
        "l1 = LSTM(64, return_sequences=True)(mask)  # the shared layer\n",
        "b1 = BatchNormalization()(l1)\n",
        "\n",
        "l2_1 = LSTM(64, return_sequences=True)(b1)  # the layer specialized in activity prediction\n",
        "b2_1 = BatchNormalization()(l2_1)\n",
        "\n",
        "l2_2 = LSTM(64)(b1)  # the layer specialized in classifcation\n",
        "b2_2 = BatchNormalization()(l2_2)\n",
        "\n",
        "act_output = Dense(num_classes, activation='softmax', name='act_output')(b2_1)\n",
        "binary_output = Dense(1, activation='sigmoid',name='binary_output')(b2_2)\n",
        "\n",
        "model = Model(inputs=[main_input], outputs=[act_output, binary_output])\n",
        "model.compile(loss={'act_output': 'categorical_crossentropy', 'binary_output': 'binary_crossentropy'},\n",
        "                      optimizer = 'adam', metrics = ['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bnE-6_8iLhVC"
      },
      "source": [
        "#Fit model\n",
        "batch_size = 64\n",
        "epochs = 5\n",
        "history = model.fit(X_train_new,{'act_output': y_train_new, 'binary_output': y_train_label},\n",
        "                         validation_data = (X_val_new,{'act_output': y_val_new, 'binary_output': y_val_label}),\n",
        "                         verbose=1,\n",
        "                         batch_size=batch_size,\n",
        "                         epochs=epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8k4-mFSRhB1o"
      },
      "source": [
        "#Plot loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('LSTM loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "20OCrE_wfXNz"
      },
      "source": [
        "# model predict\n",
        "y_pred_act1, y_pred_binary1 = model.predict(X_test_new)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eg7XfCcAWFyL"
      },
      "source": [
        "#save model\n",
        "model.save('vanilla.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKFNPZbFWEou"
      },
      "source": [
        "#load model\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/vanilla.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hWIAtNEWV_7"
      },
      "source": [
        "#discriminative report\n",
        "import sklearn\n",
        "print(sklearn.metrics.classification_report(y_test_label, t_y_pred_binary))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWPdu5OZWcvH"
      },
      "source": [
        "# autoregressive report\n",
        "print(sklearn.metrics.classification_report(y_test_new, y_pred_act))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JmsnqVoDfxXa"
      },
      "source": [
        "#Plot probability of exit for one trajectory:\n",
        "def get_x_y(number):\n",
        "  one = []\n",
        "  for item in y_pred_act[number]:\n",
        "    one.append(item[-1])\n",
        "\n",
        "  item = [np.argmax(y, axis=None, out=None) for y in X_test_new[number]]\n",
        "  item = np.ma.masked_equal(item, 0)\n",
        "  item = item.compressed()\n",
        "  lol = []\n",
        "  for e in item:\n",
        "    lol.append(e)\n",
        "  x = []\n",
        "  for i in range(len(lol)):\n",
        "    x.append(i)\n",
        "\n",
        "  y = one[-len(lol):]\n",
        "\n",
        "  return x, y\n",
        "x, y = get_x_y(9877)\n",
        "plt.plot(x, y)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_u24pqfUFsv8"
      },
      "source": [
        "## Time aware Gen and discriminative LSTM \n",
        "from keras.layers import LSTM, Dense, Masking, Input, BatchNormalization, Lambda\n",
        "from keras import  Model\n",
        "\n",
        "main_input = Input(shape = (maxlen - 1, num_classes), name = 'main_input')\n",
        "mask1 = Masking(mask_value = 0, name = 'mask1' )(main_input)\n",
        "# delta_ts: (batch_size, 1)\n",
        "delta_ts = Input(shape=(maxlen -1, ), name='delta_ts')\n",
        "mask2 = Masking(mask_value = -1, name = 'mask2' )(delta_ts)\n",
        "\n",
        "l1 = TLSTM_layer(64, return_sequence = True)(mask1, mask2)\n",
        "\n",
        "# batchnorm shared TLSTM layer output\n",
        "b1 = keras.layers.BatchNormalization()(l1)\n",
        "\n",
        "# the layer specialized in time prediction\n",
        "l2_1 = TLSTM_layer(64, return_sequence = True)(b1, mask2)\n",
        "\n",
        "# batchnorm activity prediction specialized LSTM\n",
        "b2_1 = keras.layers.BatchNormalization()(l2_1)\n",
        "\n",
        "# the layer specialized in binary classification\n",
        "l2_2a = TLSTM_layer(64)(b1, mask2)\n",
        "l2_2 = Lambda(lambda x: x[:, -1, :])(l2_2a)\n",
        "\n",
        "# batchnorm time prediction specialized TLSTM output\n",
        "b2_2 = keras.layers.BatchNormalization()(l2_2)\n",
        "\n",
        "#d2_1 = keras.layers.Dropout(rate=hparams[HP_DROPOUT])(b2_1)\n",
        "#d2_2 = keras.layers.Dropout(rate=hparams[HP_DROPOUT])(b2_2)\n",
        "\n",
        "act_output = Dense(num_classes, activation = 'softmax', name='act_output')(b2_1)\n",
        "binary_output = Dense(1, activation = 'sigmoid', name='binary_output')(b2_2)\n",
        "\n",
        "# define model\n",
        "time_model = Model(inputs=[main_input, delta_ts], outputs=[act_output, binary_output])\n",
        "\n",
        "# compile model\n",
        "time_model.compile(loss={'act_output': 'categorical_crossentropy', 'binary_output': 'binary_crossentropy'},\n",
        "                      optimizer = 'adam', metrics = ['acc'])\n",
        "time_model.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NouKER8zJa7U"
      },
      "source": [
        "from IPython.display       import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "SVG(model_to_dot(time_model, show_shapes = True, show_layer_names = True, dpi=65).create(prog='dot', format='svg'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dFvAVb38JxGl"
      },
      "source": [
        "#fit time model\n",
        "batch_size = 64,\n",
        "epochs = 5\n",
        "history_time = time_model.fit([X_train_new, X_train_delta],\n",
        "                          [y_train_new, y_train_label],\n",
        "                         validation_data = ([X_val_new, X_val_delta],\n",
        "                                             [y_val_new, y_val_label]),\n",
        "                         verbose = 1,\n",
        "                         batch_size = 64,\n",
        "                         epochs = epochs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F-1RjCIWZXs"
      },
      "source": [
        "#Plot loss\n",
        "plt.plot(history_time.history['loss'])\n",
        "plt.plot(history_time.history['val_loss'])\n",
        "plt.title('LSTM loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'val'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvNa8usuU2Xt"
      },
      "source": [
        "y_pred_act, y_pred_binary = time_model.predict([X_test_new, X_test_delta])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jHx9lP3BRkNz"
      },
      "source": [
        "# save model\n",
        "time_model.save('time_model_new.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiW8Khh9VMzB"
      },
      "source": [
        "#load model\n",
        "time_model = tf.keras.models.load_model('/content/drive/MyDrive/Colab Notebooks/Thesis/time_model_new.h5', custom_objects= {'TLSTM_layer':TLSTM_layer})"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yCRrrZBVhC4"
      },
      "source": [
        "#discriminative report\n",
        "sklearn.metrics.classification_report(y_test_label, y_pred_binary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXTlbBioVyCF"
      },
      "source": [
        "# autoregressive report\n",
        "sklearn.metrics.classification_report(y_test_new, y_pred_act)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8dyFDYJVWxn7"
      },
      "source": [
        "#Plot probability of exit for one trajectory:\n",
        "def get_x_y(number):\n",
        "  one = []\n",
        "  for item in y_pred_act_TIME_SG[number]:\n",
        "    one.append(item[-1])\n",
        "\n",
        "  item = [np.argmax(y, axis=None, out=None) for y in X_test_new[number]]\n",
        "  item = np.ma.masked_equal(item, 0)\n",
        "  item = item.compressed()\n",
        "  lol = []\n",
        "  for e in item:\n",
        "    lol.append(e)\n",
        "  x = []\n",
        "  for i in range(len(lol)):\n",
        "    x.append(i)\n",
        "\n",
        "  y = one[-len(lol):]\n",
        "\n",
        "  return x, y\n",
        "x, y = get_x_y(14002)\n",
        "plt.plot(x, y, label = 'exit risk' )\n",
        "plt.title('Single task Time LSTM')\n",
        "plt.xlabel(\"timesteps\", size=14)\n",
        "plt.ylabel(\"risk\", size=14)\n",
        "plt.legend(loc=0)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7RDmRdUQcgKZ"
      },
      "source": [
        "#AUC ROC\n",
        "from sklearn.metrics import roc_auc_score\n",
        "print('-----------')\n",
        "print('AUC ROC')\n",
        "print('Specialized LSTM')\n",
        "print(roc_auc_score(y_test_label, y_pred_binary_SD))\n",
        "print('------------')\n",
        "print('Multi LSTM')\n",
        "print(roc_auc_score(y_test_label, y_pred_binary1))\n",
        "print('------------')\n",
        "print('Multi Time LSTM')\n",
        "print(roc_auc_score(y_test_label, y_pred_binary))\n",
        "print('-------------')\n",
        "print('Multi Time LSTM')\n",
        "print(roc_auc_score(y_test_label, y_pred_binary_TIME_SD))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uURj9gdGnEmq"
      },
      "source": [
        "#Perplexity\n",
        "from keras import backend as K\n",
        "def ppl_e(y_true, y_pred):\n",
        "    return K.exp(K.mean(K.categorical_crossentropy(y_true, y_pred)))\n",
        "print('-------------')\n",
        "print('Time LSTM')\n",
        "print(ppl_e(y_test_new,y_pred_act))\n",
        "print('-------------')\n",
        "print('Multi LSTM')\n",
        "print(ppl_e(y_test_new,y_pred_act1))\n",
        "print('--------------')\n",
        "print('Specialized LSTM')\n",
        "print(ppl_e(y_test_new,y_pred_act_SG))\n",
        "print('--------------')\n",
        "print('Specialized TIME LSTM')\n",
        "print(ppl_e(y_test_new,y_pred_act_TIME_SG))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOcq8qEJtfWY"
      },
      "source": [
        "#ROC CURVE MULTIPLR\n",
        "from sklearn import metrics\n",
        "plt.figure(0).clf()\n",
        "\n",
        "fpr, tpr, thresh = metrics.roc_curve(y_test_label, y_pred_binary_SD)\n",
        "auc = metrics.roc_auc_score(y_test_label, y_pred_binary_SD)\n",
        "plt.plot(fpr,tpr,label=\"LSTM_S\")\n",
        "\n",
        "fpr, tpr, thresh = metrics.roc_curve(y_test_label,y_pred_binary1)\n",
        "auc = metrics.roc_auc_score(y_test_label, y_pred_binary1)\n",
        "plt.plot(fpr,tpr,label=\"Multi-task LSTM\")\n",
        "\n",
        "fpr, tpr, thresh = metrics.roc_curve(y_test_label, y_pred_binary)\n",
        "auc = metrics.roc_auc_score(y_test_label, y_pred_binary)\n",
        "plt.plot(fpr,tpr,label=\"Multi_task T-LSTM\")\n",
        "\n",
        "fpr, tpr, thresh = metrics.roc_curve(y_test_label, y_pred_binary)\n",
        "auc = metrics.roc_auc_score(y_test_label, y_pred_binary_TIME_SD)\n",
        "plt.plot(fpr,tpr,label=\"Multi_task T-LSTM\")\n",
        "plt.xlabel(\"FPR\", size=14)\n",
        "plt.ylabel(\"TPR\", size=14)\n",
        "plt.title(\"ROC curves\")\n",
        "plt.plot([0,1], [0,1], linestyle='--', label='No Skill, auc =0.5')\n",
        "plt.legend(loc=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTNSoZKBrbVN"
      },
      "source": [
        "#POst-Processsing\n",
        "#random choice\n",
        "\n",
        "def make_y_sequences(y_pred_act):\n",
        "  random_pred = []\n",
        "  real_pred = []\n",
        "  for i in range(len(y_pred_act)):\n",
        "    item = [np.argmax(y, axis=None, out=None) for y in y_test_new[i]]\n",
        "    item = np.ma.masked_equal(item, 0)\n",
        "    item = item.compressed()\n",
        "    real_pred.append(item)\n",
        "    l = len(item)\n",
        "    ns = []\n",
        "    for r in y_pred_act[i][-l:]:\n",
        "      wow =np.random.choice(r, p=r)\n",
        "      for i in range(len(r)):\n",
        "        if r[i] == wow:\n",
        "          ns.append(i)\n",
        "    random_pred.append(ns)\n",
        "  return random_pred, real_pred\n",
        "random_pred, real_pred = make_y_sequences(y_pred_act)\n",
        "random_pred1, real_pred = make_y_sequences(y_pred_act1)\n",
        "random_pred_SG, real_pred = make_y_sequences(y_pred_act_SG)\n",
        "random_pred_TIME_SG, real_pred = make_y_sequences(y_pred_act_TIME_SG)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5kUTNylpSA2"
      },
      "source": [
        "#DL distance from https://stackabuse.com/levenshtein-distance-and-text-similarity-in-python/\n",
        "import numpy as np\n",
        "\n",
        "def levenshtein(seq1, seq2):\n",
        "    size_x = len(seq1) + 1\n",
        "    size_y = len(seq2) + 1\n",
        "    matrix = np.zeros ((size_x, size_y))\n",
        "    for x in range(size_x):\n",
        "        matrix [x, 0] = x\n",
        "    for y in range(size_y):\n",
        "        matrix [0, y] = y\n",
        "\n",
        "    for x in range(1, size_x):\n",
        "        for y in range(1, size_y):\n",
        "            if seq1[x-1] == seq2[y-1]:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1, y] + 1,\n",
        "                    matrix[x-1, y-1],\n",
        "                    matrix[x, y-1] + 1\n",
        "                )\n",
        "            else:\n",
        "                matrix [x,y] = min(\n",
        "                    matrix[x-1,y] + 1,\n",
        "                    matrix[x-1,y-1] + 1,\n",
        "                    matrix[x,y-1] + 1\n",
        "                )\n",
        "    return (matrix[size_x - 1, size_y - 1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PJPsnemno_sE",
        "outputId": "eb9b2839-8648-433f-f781-f970414f5b4e"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Activation, Dropout, Flatten, MaxPooling2D\n",
        "from keras.layers.convolutional import Conv2D \n",
        "from keras.layers.recurrent import SimpleRNN, LSTM, GRU \n",
        "from keras.utils import np_utils\n",
        "from keras import backend as K\n",
        "\n",
        "from distutils.version import LooseVersion as LV\n",
        "from keras import __version__\n",
        "\n",
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "\n",
        "from keras.datasets import mnist, fashion_mnist, imdb\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "print('Using Keras version:', __version__, 'backend:', K.backend())\n",
        "assert(LV(__version__) >= LV(\"2.0.0\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using Keras version: 2.4.3 backend: tensorflow\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6dp_GGhn0jP",
        "outputId": "74c227d5-f578-49fd-9af2-e0f5bd89e4b0"
      },
      "source": [
        "if K.backend() == \"tensorflow\":\n",
        "    import tensorflow as tf\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "    if device_name == '':\n",
        "        device_name = \"None\"\n",
        "    print('Using TensorFlow version:', tf.__version__, ', GPU:', device_name)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow version: 2.4.1 , GPU: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0HZwlgiGIUQ"
      },
      "source": [
        "#distance similarity array\n",
        "distances = []\n",
        "distances1 = []\n",
        "distances_SG = []\n",
        "distances_TIME_SG = []\n",
        "for ps, rs in zip(random_pred, real_pred):\n",
        "    distances.append(levenshtein(ps, rs))\n",
        "for ps, rs in zip(random_pred1, real_pred):\n",
        "    distances1.append(levenshtein(ps, rs))\n",
        "for ps, rs in zip(random_pred_SG, real_pred):\n",
        "    distances_SG.append(levenshtein(ps, rs))\n",
        "for ps, rs in zip(random_pred_TIME_SG, real_pred):\n",
        "    distances_TIME_SG.append(levenshtein(ps, rs))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyx0JkCErMY4"
      },
      "source": [
        "# DL mean\n",
        "print('DL mean')\n",
        "print('---------')\n",
        "print('Multi-task TIME lstm')\n",
        "print(np.mean(distances))\n",
        "print('---------')\n",
        "print('Multi-task lstm')\n",
        "print(np.mean(distances1))\n",
        "print('---------')\n",
        "print('Single-task lstm')\n",
        "print(np.mean(distances_SG))\n",
        "print('---------')\n",
        "print('Single-task TIME lstm')\n",
        "print(np.mean(distances_TIME_SG))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HhwNO1nFDa1j"
      },
      "source": [
        "#---------------END OF CODE---------------------#"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}